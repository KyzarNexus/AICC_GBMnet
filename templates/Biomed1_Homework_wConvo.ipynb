{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HfEJTXfyfjI",
    "outputId": "3619bed4-4c08-41d9-d616-aa87f4589b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mnist in c:\\users\\kyzar\\anaconda3\\envs\\aicc\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kyzar\\anaconda3\\envs\\aicc\\lib\\site-packages (from mnist) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#Hello everyone!  Welcome to the biomedical imaging team 1 homework introduction to python and programming neural networks!\n",
    "#I'll walk you through an example using the mnist dataset.\n",
    "#First, we need to install mnist as it is not included in Google Colab by default.\n",
    "#The \"!\" at the start of this line instructs Colab to execute a shell command.\n",
    "%pip install mnist\n",
    "#Now, mnist should be downloaded and installed as a python package.  \n",
    "#Python has a variety of packages that add reusable functionality of many kinds.\n",
    "\n",
    "#Now we need to import the \"mnist\" package.\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "#These are calls to the python \"print\" function which display text to the screen.\n",
    "#Also make note of the python \".\" operator which is used to reference items inside objects, such as packages.\n",
    "#The function \"mnist.train_images\" returns a Numpy array with the data.\n",
    "#Numpy arrays can have multiple dimensions.  Their size on each axis is described by the \"shape\" attribute.\n",
    "#Let's look at the shapes of the images and labels.\n",
    "# print(mnist.train_images().shape)\n",
    "# print(mnist.test_images().shape)\n",
    "# print(mnist.train_labels().shape)\n",
    "# print(mnist.test_labels().shape)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQad8mdvXH0G"
   },
   "source": [
    "Based on the returned information, how many images are present?  What is the size of each image?  How are these images labeled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "VzyRtGYnzv2_",
    "outputId": "ce0f8aed-de50-4a10-9f13-6d6554e7d647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1861e45d390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAanklEQVR4nO3df2xU95nv8c9gYDBoPKpL7BkHx3Uj2HQx4qpAAIsfJrdYeFsW4nRFklUXtCk3aQwScqLcUqSLt9LiiArEailkk3YpbKAgrYCwhQ1xBTZNibsOIoqXplxyMcUNdr1Y4DEOGWP47h9cph0wpmcy48czfr+kkeKZ83C+nJ7y5jDjY59zzgkAAAMjrBcAABi+iBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADAz0noBd7t165YuXbqkQCAgn89nvRwAgEfOOXV3d6ugoEAjRgx8rTPkInTp0iUVFhZaLwMA8Dm1trZqwoQJA24z5CIUCAQkSXP0FxqpUcarAQB41acbeldHYn+eDyRlEdq2bZt+8IMfqK2tTZMnT9aWLVs0d+7cB87d+Se4kRqlkT4iBABp5//fkfRPeUslJR9M2Ldvn9asWaN169bp9OnTmjt3rioqKnTx4sVU7A4AkKZSEqHNmzfrueee07e//W195Stf0ZYtW1RYWKjt27enYncAgDSV9Aj19vbq1KlTKi8vj3u+vLxcJ0+evGf7aDSqSCQS9wAADA9Jj9Dly5d18+ZN5efnxz2fn5+v9vb2e7avra1VMBiMPfhkHAAMHyn7ZtW735ByzvX7JtXatWvV1dUVe7S2tqZqSQCAISbpn44bP368srKy7rnq6ejouOfqSJL8fr/8fn+ylwEASANJvxIaPXq0pk2bprq6urjn6+rqVFpamuzdAQDSWEq+T6i6ulrf+ta3NH36dM2ePVuvv/66Ll68qBdeeCEVuwMApKmURGjZsmXq7OzU97//fbW1tamkpERHjhxRUVFRKnYHAEhTPuecs17EH4tEIgoGgyrTEu6YAABpqM/dUL3eUldXl3Jycgbclh/lAAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJgZab0ADC+t/1rieaZ59i7PM4/9S5XnGUn68nffS2gOQGK4EgIAmCFCAAAzSY9QTU2NfD5f3CMUCiV7NwCADJCS94QmT56sn//857Gvs7KyUrEbAECaS0mERo4cydUPAOCBUvKe0Llz51RQUKDi4mI9/fTTOn/+/H23jUajikQicQ8AwPCQ9AjNnDlTu3bt0tGjR/XGG2+ovb1dpaWl6uzs7Hf72tpaBYPB2KOwsDDZSwIADFFJj1BFRYWeeuopTZkyRV/72td0+PBhSdLOnTv73X7t2rXq6uqKPVpbW5O9JADAEJXyb1YdN26cpkyZonPnzvX7ut/vl9/vT/UyAABDUMq/Tygajeqjjz5SOBxO9a4AAGkm6RF6+eWX1dDQoJaWFv3qV7/SN7/5TUUiES1fvjzZuwIApLmk/3Pc7373Oz3zzDO6fPmyHnroIc2aNUuNjY0qKipK9q4AAGku6RHau3dvsn9JZJDrXWM8z9yS8zxz4tkfeJ6RpL9989ueZ279528S2hcA7h0HADBEhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJhJ+Q+1A/7Yn70W9T60yPtIXtZY70OS3Bj+LwEMJq6EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIZbBmNQRXP91ksYVrJychKauzH1Uc8zn8zL9jxT/M/nPc/0tbV7nsHQxZUQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5hiUN2s7hyU/fwymtjfr7I6uz3P9CW0p8Hxm9qvJDR3dum2JK+kf899Y4Hnmd/PTsFCYIYrIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADDcwRcJuln3V88y//vk/ep4ZoWzPM//rze94npGkopb3EpobDJ8tftzzzPkn/ymhfd10Ps8z264We55pfrPE80yeTnqewdDFlRAAwAwRAgCY8RyhEydOaPHixSooKJDP59PBgwfjXnfOqaamRgUFBcrOzlZZWZnOnDmTrPUCADKI5wj19PRo6tSp2rp1a7+vb9y4UZs3b9bWrVvV1NSkUCikhQsXqrvb+w8LAwBkNs8fTKioqFBFRUW/rznntGXLFq1bt06VlZWSpJ07dyo/P1979uzR888///lWCwDIKEl9T6ilpUXt7e0qLy+PPef3+zV//nydPNn/J1qi0agikUjcAwAwPCQ1Qu3t7ZKk/Pz8uOfz8/Njr92ttrZWwWAw9igsLEzmkgAAQ1hKPh3n88V/j4Fz7p7n7li7dq26urpij9bW1lQsCQAwBCX1m1VDoZCk21dE4XA49nxHR8c9V0d3+P1++f3+ZC4DAJAmknolVFxcrFAopLq6uthzvb29amhoUGlpaTJ3BQDIAJ6vhK5du6aPP/449nVLS4s++OAD5ebm6pFHHtGaNWu0YcMGTZw4URMnTtSGDRs0duxYPfvss0ldOAAg/XmO0Pvvv68FCxbEvq6urpYkLV++XD/5yU/0yiuv6Pr163rxxRd15coVzZw5U++8844CgUDyVg0AyAieI1RWVibn3H1f9/l8qqmpUU1NzedZF9LAha97fy/vCyPGeJ65pfufb/dT9H+G7o1IE3Vlkve3cG+6Wwntq7n3hueZf5/zZc8zeVe4Gelwx73jAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYCapP1kV6cmVTk1o7p8qX0/ySvp3oCd3UPaDP/jMJXDH7itXUrASZDquhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM9zAFPr4mTEJzc0b0+t5puvWZ55n/v6Hf+15JqSTnmeGuj+v/M2g7avmwl8mMPVJ0teBzMeVEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghhuYZpiRX3rE88wbf/GjFKykf3/1m2c9z4T+IfNuRpqI4Kjrg7avET7neeZ3L5V6nhnd5X0/X/zRe55nMHRxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGphmmZ3K+55myMTcS3JvP88TVAw97ngn9j3GeZ0ZcveZ5RpKixeM9z/SNzfI8c2Wl9/UdeXi355ksX2J/z/y3ST/zPlSd0K68+zvvI43RxHb1t00rPM988cBYzzOBvY2eZzIFV0IAADNECABgxnOETpw4ocWLF6ugoEA+n08HDx6Me33FihXy+Xxxj1mzZiVrvQCADOI5Qj09PZo6daq2bt16320WLVqktra22OPIkSOfa5EAgMzk+YMJFRUVqqioGHAbv9+vUCiU8KIAAMNDSt4Tqq+vV15eniZNmqSVK1eqo6PjvttGo1FFIpG4BwBgeEh6hCoqKrR7924dO3ZMmzZtUlNTk5544glFo/1/RrK2tlbBYDD2KCwsTPaSAABDVNK/T2jZsmWx/y4pKdH06dNVVFSkw4cPq7Ky8p7t165dq+rqP3yDQSQSIUQAMEyk/JtVw+GwioqKdO7cuX5f9/v98vv9qV4GAGAISvn3CXV2dqq1tVXhcDjVuwIApBnPV0LXrl3Txx9/HPu6paVFH3zwgXJzc5Wbm6uamho99dRTCofDunDhgr73ve9p/PjxevLJJ5O6cABA+vMcoffff18LFiyIfX3n/Zzly5dr+/btam5u1q5du3T16lWFw2EtWLBA+/btUyAQSN6qAQAZweecc9aL+GORSETBYFBlWqKRvlHWy0k70a/P8DxT9/prKVhJ//7vjd5B2c9/3fR+01NJKhnd7XkmOGJMQvsaDCMSuMmsJH1y81PPM5f6sj3PjPH1eZ6ZPNr7W9mJHodb8v7H48W+655nFr/+iueZwr8/6XlmsPS5G6rXW+rq6lJOTs6A23LvOACAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJjhLtoZZmQ45Hmm6NDVhPb1DwW/TGhuMAzmXZOHsteufjmhuZ89N9/7UOOHnkeyvvAFzzOX//IxzzOJupnAD32e+3yT55lHx/yX55mfTfZ+7AYLd9EGAKQFIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMNzCFRgQCCc39/q9LPM/0FCa0q0Hz5X1XPM+M6Ix4nvnkqS95nmn63//oeWbVJ3M8z0jShcevJzQHacSYMZ5nfMGBb/LZn5u/7/A8M1i4gSkAIC0QIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGZGWi8A9m51dyc099Br73mfSWhPg+fWIM34rxYlMIV0cOuzz7wPJTKTIbgSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcANTwMAXj/4/zzO7vxf2PPM343/peUaSNhQ/6Xmmr+W3Ce0LwxtXQgAAM0QIAGDGU4Rqa2s1Y8YMBQIB5eXlaenSpTp79mzcNs451dTUqKCgQNnZ2SorK9OZM2eSumgAQGbwFKGGhgZVVVWpsbFRdXV16uvrU3l5uXp6emLbbNy4UZs3b9bWrVvV1NSkUCikhQsXqjvBH5wGAMhcnj6Y8Pbbb8d9vWPHDuXl5enUqVOaN2+enHPasmWL1q1bp8rKSknSzp07lZ+frz179uj5559P3soBAGnvc70n1NXVJUnKzc2VJLW0tKi9vV3l5eWxbfx+v+bPn6+TJ0/2+2tEo1FFIpG4BwBgeEg4Qs45VVdXa86cOSopKZEktbe3S5Ly8/Pjts3Pz4+9drfa2loFg8HYo7CwMNElAQDSTMIRWrVqlT788EP99Kc/vec1n88X97Vz7p7n7li7dq26urpij9bW1kSXBABIMwl9s+rq1at16NAhnThxQhMmTIg9HwqFJN2+IgqH//CNdR0dHfdcHd3h9/vl9/sTWQYAIM15uhJyzmnVqlXav3+/jh07puLi4rjXi4uLFQqFVFdXF3uut7dXDQ0NKi0tTc6KAQAZw9OVUFVVlfbs2aO33npLgUAg9j5PMBhUdna2fD6f1qxZow0bNmjixImaOHGiNmzYoLFjx+rZZ59NyW8AAJC+PEVo+/btkqSysrK453fs2KEVK1ZIkl555RVdv35dL774oq5cuaKZM2fqnXfeUSAQSMqCAQCZw+ecc9aL+GORSETBYFBlWqKRvlHWywGGjC/9R7bnmW0PJ3YD068v+RvPM+79/0xoX8g8fe6G6vWWurq6lJOTM+C23DsOAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZhL6yaoABt9/tBV5H0rwLtrAYOFKCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwww1MgTSR9W9f8D40PbF9/X5WjueZvPcT2xeGN66EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz3MAUSBNf/NF7nmcWPbMkoX31jUloDPCMKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MAUy2Ij/2ZrQXIESmwO84koIAGCGCAEAzHiKUG1trWbMmKFAIKC8vDwtXbpUZ8+ejdtmxYoV8vl8cY9Zs2YlddEAgMzgKUINDQ2qqqpSY2Oj6urq1NfXp/LycvX09MRtt2jRIrW1tcUeR44cSeqiAQCZwdMHE95+++24r3fs2KG8vDydOnVK8+bNiz3v9/sVCoWSs0IAQMb6XO8JdXV1SZJyc3Pjnq+vr1deXp4mTZqklStXqqOj476/RjQaVSQSiXsAAIaHhCPknFN1dbXmzJmjkpKS2PMVFRXavXu3jh07pk2bNqmpqUlPPPGEotFov79ObW2tgsFg7FFYWJjokgAAacbnnHOJDFZVVenw4cN69913NWHChPtu19bWpqKiIu3du1eVlZX3vB6NRuMCFYlEVFhYqDIt0UjfqESWBgAw1OduqF5vqaurSzk5OQNum9A3q65evVqHDh3SiRMnBgyQJIXDYRUVFencuXP9vu73++X3+xNZBgAgzXmKkHNOq1ev1oEDB1RfX6/i4uIHznR2dqq1tVXhcDjhRQIAMpOn94Sqqqr05ptvas+ePQoEAmpvb1d7e7uuX78uSbp27Zpefvllvffee7pw4YLq6+u1ePFijR8/Xk8++WRKfgMAgPTl6Upo+/btkqSysrK453fs2KEVK1YoKytLzc3N2rVrl65evapwOKwFCxZo3759CgQCSVs0ACAzeP7nuIFkZ2fr6NGjn2tBAIDhg3vHAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMjLRewN2cc5KkPt2QnPFiAACe9emGpD/8eT6QIReh7u5uSdK7OmK8EgDA59Hd3a1gMDjgNj73p6RqEN26dUuXLl1SIBCQz+eLey0SiaiwsFCtra3KyckxWqE9jsNtHIfbOA63cRxuGwrHwTmn7u5uFRQUaMSIgd/1GXJXQiNGjNCECRMG3CYnJ2dYn2R3cBxu4zjcxnG4jeNwm/VxeNAV0B18MAEAYIYIAQDMpFWE/H6/1q9fL7/fb70UUxyH2zgOt3EcbuM43JZux2HIfTABADB8pNWVEAAgsxAhAIAZIgQAMEOEAABm0ipC27ZtU3FxscaMGaNp06bpF7/4hfWSBlVNTY18Pl/cIxQKWS8r5U6cOKHFixeroKBAPp9PBw8ejHvdOaeamhoVFBQoOztbZWVlOnPmjM1iU+hBx2HFihX3nB+zZs2yWWyK1NbWasaMGQoEAsrLy9PSpUt19uzZuG2Gw/nwpxyHdDkf0iZC+/bt05o1a7Ru3TqdPn1ac+fOVUVFhS5evGi9tEE1efJktbW1xR7Nzc3WS0q5np4eTZ06VVu3bu339Y0bN2rz5s3aunWrmpqaFAqFtHDhwth9CDPFg46DJC1atCju/DhyJLPuwdjQ0KCqqio1Njaqrq5OfX19Ki8vV09PT2yb4XA+/CnHQUqT88Gliccff9y98MILcc899thj7rvf/a7Rigbf+vXr3dSpU62XYUqSO3DgQOzrW7duuVAo5F599dXYc5999pkLBoPutddeM1jh4Lj7ODjn3PLly92SJUtM1mOlo6PDSXINDQ3OueF7Ptx9HJxLn/MhLa6Eent7derUKZWXl8c9X15erpMnTxqtysa5c+dUUFCg4uJiPf300zp//rz1kky1tLSovb097tzw+/2aP3/+sDs3JKm+vl55eXmaNGmSVq5cqY6ODuslpVRXV5ckKTc3V9LwPR/uPg53pMP5kBYRunz5sm7evKn8/Py45/Pz89Xe3m60qsE3c+ZM7dq1S0ePHtUbb7yh9vZ2lZaWqrOz03ppZu787z/czw1Jqqio0O7du3Xs2DFt2rRJTU1NeuKJJxSNRq2XlhLOOVVXV2vOnDkqKSmRNDzPh/6Og5Q+58OQu4v2QO7+0Q7OuXuey2QVFRWx/54yZYpmz56tRx99VDt37lR1dbXhyuwN93NDkpYtWxb775KSEk2fPl1FRUU6fPiwKisrDVeWGqtWrdKHH36od999957XhtP5cL/jkC7nQ1pcCY0fP15ZWVn3/E2mo6Pjnr/xDCfjxo3TlClTdO7cOeulmLnz6UDOjXuFw2EVFRVl5PmxevVqHTp0SMePH4/70S/D7Xy433Hoz1A9H9IiQqNHj9a0adNUV1cX93xdXZ1KS0uNVmUvGo3qo48+Ujgctl6KmeLiYoVCobhzo7e3Vw0NDcP63JCkzs5Otba2ZtT54ZzTqlWrtH//fh07dkzFxcVxrw+X8+FBx6E/Q/Z8MPxQhCd79+51o0aNcj/+8Y/dr3/9a7dmzRo3btw4d+HCBeulDZqXXnrJ1dfXu/Pnz7vGxkb3jW98wwUCgYw/Bt3d3e706dPu9OnTTpLbvHmzO336tPvtb3/rnHPu1VdfdcFg0O3fv981Nze7Z555xoXDYReJRIxXnlwDHYfu7m730ksvuZMnT7qWlhZ3/PhxN3v2bPfwww9n1HH4zne+44LBoKuvr3dtbW2xx6effhrbZjicDw86Dul0PqRNhJxz7oc//KErKipyo0ePdl/96lfjPo44HCxbtsyFw2E3atQoV1BQ4CorK92ZM2esl5Vyx48fd5LueSxfvtw5d/tjuevXr3ehUMj5/X43b94819zcbLvoFBjoOHz66aeuvLzcPfTQQ27UqFHukUceccuXL3cXL160XnZS9ff7l+R27NgR22Y4nA8POg7pdD7woxwAAGbS4j0hAEBmIkIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDM/Dcd8vZSU8nn0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Like we discussed in the last meeting, data is the more involved and difficult part of data science.\n",
    "#Let's make sure we examine our data before we start training.\n",
    "\n",
    "#This line isn't python.  It's a special instruction to the Jupyter notebook to allow us to use matplotlib to make figures in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "#We also need to import some more python packages.  Notice the use of \"from\" here.\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "#We want to select an image to plot at random.  To do this, we need to generate a random number using Numpy.\n",
    "#Here, we use python's \"range\" function to make a list of numbers from 0 to NUMBER_OF_IMAGES.\n",
    "#PLEASE replace NUMBER_OF_IMAGES with the actual number of images in the training portion of the dataset.\n",
    "#\"range\" returns an \"iterator\" object.  We need this to be a \"list\" object, so we make it one.\n",
    "indexes = list(range(60000))\n",
    "i = numpy.random.choice(indexes)\n",
    "\n",
    "#Now we will \"imshow\" the i'th image of the train_images.\n",
    "pyplot.imshow(train_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prHA9J5HZNhp",
    "outputId": "4da0045d-bda9-42b1-bef3-cb6e257461c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "#Did you see how the images were labeled?  This is important!\n",
    "#Let's have a look at the first 10 labels.\n",
    "#We can do this using python slices, \"array[start:stop]\".\n",
    "# train_labels = mnist.train_labels()\n",
    "print(train_labels[0:10])\n",
    "#Notice two things.  First, slicing produced a small, \"slice\" of the array.\n",
    "#Second.  The images are labeled by the number represented.\n",
    "#This is actually not good for neural networks.\n",
    "#We want to classify each image according to the written number, but the current labels imply a numerical relationship.\n",
    "#We don't usually want o imply a > or < relationship during a classification problem.\n",
    "#To fix this and help our neural network perform better, we will change this to one-hot-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ds0oYE3EbRtf"
   },
   "outputs": [],
   "source": [
    "#One-hot-encoding will represent 5 as 0000010000.\n",
    "# 3 = 0001000000\n",
    "# 9 = 0000000001\n",
    "\n",
    "#Let's make a python function for one-hot-encoding the digits.\n",
    "\n",
    "def one_hot(label):\n",
    "  new_label = numpy.zeros(10)\n",
    "  new_label[label] = 1\n",
    "  return new_label\n",
    "\n",
    "#Python cares about whitespace!\n",
    "#Python separates the inside of functions, loops, if statements, etc by their indentation level.\n",
    "#If your indentation is off, python will complain!\n",
    "#This unique syntax helps python be more readable.\n",
    "\n",
    "#Try using this function with a few digits to make sure the function works like we want it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jfGoKEKgccd2"
   },
   "outputs": [],
   "source": [
    "# We need another function to give one-hot-encodings to all the labels in a list of labels.\n",
    "def one_hot_array(labels):\n",
    "  #Let's make an empty list to store our results.\n",
    "  new_labels = []\n",
    "  \n",
    "  #We'll use a \"for\" loop to look at each label in the list.\n",
    "  for label in labels:\n",
    "    new_labels.append(one_hot(label))\n",
    "\n",
    "  #Before we're done, we need to turn the list into a numpy array.  We almost always use numpy arrays with neural networks.\n",
    "  return numpy.asarray(new_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tR5tYcehIy0"
   },
   "source": [
    "Each of the trainable parameters in this model represents a weight or bias for one of it's artificial neurons.  When we train the neural network, we adjust the weights until the neural network learns to give correct answers.\n",
    "\n",
    "How many trainable parameters are in this model?\n",
    "How many non-trainable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iYJODsFpqeT"
   },
   "source": [
    "There are some problems with this model.  Neural networks with this structure are called multi-layer perceptrons (MLPs).  MLPs are very sensitive to exactly where things are in the image.  For instance, moving a cat slightly to the left might confuse the network into thinking it is no longer a cat.  Also, these networks have a very large number of trainable parameters.\n",
    "\n",
    "We can solve these problems with a convolutional neural network (CNN).  CNNs look for patterns whereever they appear in the image.  In this way, they are no longer sensitive to position.  They also \"reuse\" pattern-finding neurons by using them in small patches that slide across the entire image.  CNNs are the innovation that allowed computer vision to take off the way it has.\n",
    "\n",
    "Look at this YouTube video to see how a CNN reuses neurons.  https://www.youtube.com/watch?v=KTB_OFoAQcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FbNMndKUpoZB"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Now, let's finally build a computer vision neural network!\n",
    "#We'll use the \"keras\" package for this.\n",
    "#We need a few things \"from\" keras.\n",
    "from keras import Model\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "#A convolutional neural network is just a network that has one or more Convolutional layers in it.\n",
    "from keras.layers import Conv2D\n",
    "#It also typically includes pooling layers that reduce the size of an image.\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "#Let's make a network like the one we saw above.\n",
    "#Note that our input shape has changed slightly.\n",
    "image = Input(shape=(28, 28, 1))\n",
    "\n",
    "#yow, let's make our first convolution layer followed by our first pooling layer.\n",
    "#This network will 16 neurons (convolution filters).\n",
    "#Each filter will be 3x3.\n",
    "#We'll use a 'relu' activation and 'same' padding.\n",
    "conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')\n",
    "conv1 = conv1(image)\n",
    "\n",
    "#Next, pooling.\n",
    "#The default pool size is 2x2 and shrinks the image by half on each dimension.\n",
    "pool1 = MaxPooling2D()\n",
    "pool1 = pool1(conv1)\n",
    "\n",
    "#Now you create the second convolution and second pooling layers.\n",
    "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling2D()(conv2)\n",
    "\n",
    "#Now we have a nice feature map.\n",
    "#Next we flatten the data.  This is when our data will stop being an image and start being an array.\n",
    "#You can think of this as when the neural network stops \"seeing\" and starts \"thinking about what it saw.\"\n",
    "flat = Flatten()\n",
    "flat = flat(pool2)\n",
    "\n",
    "#Adding Dense layers will let us think about what we saw and answer the questions we care about.\n",
    "dense1 = Dense(100, activation='relu')\n",
    "dense1 = dense1(flat)\n",
    "\n",
    "#Please make the final classifier layer here:\n",
    "dense2 = Dense(10, activation='softmax')(dense1)\n",
    "\n",
    "model = Model(image, dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h77Y94bouxBr",
    "outputId": "ed03a555-99d8-41ae-95e8-7c50f1141371"
   },
   "outputs": [],
   "source": [
    "#Go ahead and look at the model's summary and produce a plot of the model.\n",
    "model.summary()\n",
    "#How does the number of parameters compare between the CNN and the MLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxrTXF_Ku2ga"
   },
   "outputs": [],
   "source": [
    "#CNNs compile the same as other neural networks.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHz3oKczvJJp",
    "outputId": "a6f1956e-61c6-48b8-ef1e-24c4628c0d76"
   },
   "outputs": [],
   "source": [
    "#Now let's train the model.\n",
    "#Remember, our input shape is a bit different.\n",
    "#CNNs requrie the shape to be (28, 28, 1) instead of (28, 28).\n",
    "#We use numpy.expand_dims to add the extra \"1\".\n",
    "model.fit(numpy.expand_dims(train_images, axis=-1), one_hot_array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmRkvCDwwOKy",
    "outputId": "98ffed5a-e6f0-4f84-bb29-34bfdc7ec7fa"
   },
   "outputs": [],
   "source": [
    "#Let's see how the model performed.\n",
    "model.evaluate(numpy.expand_dims(mnist.test_images(), axis=-1), one_hot_array(mnist.test_labels()))\n",
    "#How did the CNN's performance compare to the MLP's?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary placeholder for batching\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.datasets import mnist\n",
    "from keras import Model\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import MaxPooling3D\n",
    "import tensorflow as tf\n",
    "import GBMnet_batch # Batching class. \n",
    "from GBMnet_helpers import * # Helper functions\n",
    "\n",
    "class GBMnet_batch(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, ImgX, ImgY, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.ImgX, self.ImgY = ImgX, ImgY\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        low = idx * self.batch_size\n",
    "        # Cap upper bound at array length; the last batch may be smaller\n",
    "        # if the total number of items is not a multiple of batch size.\n",
    "        high = min(low + self.batch_size, len(self.x))\n",
    "        batch_x = self.x[low:high]\n",
    "        batch_y = self.y[low:high]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (254, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)\n",
    "\n",
    "def one_hot(label):\n",
    "  new_label = np.zeros(10)\n",
    "  new_label[label] = 1\n",
    "  return new_label\n",
    "\n",
    "def one_hot_array(labels):\n",
    "  #Let's make an empty list to store our results.\n",
    "  new_labels = []\n",
    "  \n",
    "  #We'll use a \"for\" loop to look at each label in the list.\n",
    "  for label in labels:\n",
    "    new_labels.append(one_hot(label))\n",
    "\n",
    "  #Before we're done, we need to turn the list into a numpy array.  We almost always use numpy arrays with neural networks.\n",
    "  return np.asarray(new_labels)\n",
    "\n",
    "\n",
    "# Import\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Summary Information\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "### CNN Parameters\n",
    "xImage = 254\n",
    "yImage = 254\n",
    "batchSize = 10000\n",
    "\n",
    "### Batching\n",
    "batchedData = GBMnet_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
